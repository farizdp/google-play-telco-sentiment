{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Scrape Google Play Reviews\n",
    "\n",
    "Scrape reviews for 3 Indonesian telco apps:\n",
    "- **MyTelkomsel** (`com.telkomsel.telkomselcm`)\n",
    "- **myXL** (`com.apps.MyXL`)\n",
    "- **myIM3** (`com.pure.indosat.care`)\n",
    "\n",
    "**Parameters:** English language, Indonesia country, max 10,000 reviews per app, last 3 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google_play_scraper import Sort, reviews\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# App configurations\nAPPS = {\n    \"MyTelkomsel\": \"com.telkomsel.telkomselcm\",\n    \"myXL\": \"com.apps.MyXL\",\n    \"myIM3\": \"com.pure.indosat.care\",\n}\n\n# Scraping parameters\nLANG = \"en\"\nCOUNTRY = \"id\"\nMAX_REVIEWS = 10000\nBATCH_SIZE = 200\nDATE_CUTOFF = datetime.now() - timedelta(days=90)  # Last 3 months\n\n# Version/date tag for output files\nRUN_DATE = datetime.now().strftime(\"%Y%m%d\")\n\n# Output directory\nOUTPUT_DIR = \"data/raw\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(f\"Date cutoff: {DATE_CUTOFF.strftime('%Y-%m-%d')}\")\nprint(f\"Max reviews per app: {MAX_REVIEWS}\")\nprint(f\"Output file tag: {RUN_DATE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_app_reviews(app_name, app_id):\n",
    "    \"\"\"Scrape reviews for a single app with date filtering.\"\"\"\n",
    "    all_reviews = []\n",
    "    token = None\n",
    "    \n",
    "    pbar = tqdm(total=MAX_REVIEWS, desc=f\"Scraping {app_name}\")\n",
    "    \n",
    "    while len(all_reviews) < MAX_REVIEWS:\n",
    "        try:\n",
    "            batch, token = reviews(\n",
    "                app_id,\n",
    "                lang=LANG,\n",
    "                country=COUNTRY,\n",
    "                sort=Sort.NEWEST,\n",
    "                count=BATCH_SIZE,\n",
    "                continuation_token=token,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError fetching {app_name}: {e}\")\n",
    "            break\n",
    "        \n",
    "        if not batch:\n",
    "            print(f\"\\nNo more reviews for {app_name}.\")\n",
    "            break\n",
    "        \n",
    "        # Filter by date\n",
    "        for review in batch:\n",
    "            review_date = review[\"at\"]\n",
    "            if review_date >= DATE_CUTOFF:\n",
    "                all_reviews.append(review)\n",
    "            else:\n",
    "                # Reviews are sorted newest first, so we can stop\n",
    "                pbar.update(pbar.total - pbar.n)  # Fill progress bar\n",
    "                pbar.close()\n",
    "                print(f\"Reached date cutoff for {app_name}. Got {len(all_reviews)} reviews.\")\n",
    "                return all_reviews\n",
    "        \n",
    "        pbar.update(len(batch))\n",
    "        time.sleep(1)  # Rate limiting\n",
    "    \n",
    "    pbar.close()\n",
    "    print(f\"Finished {app_name}. Got {len(all_reviews)} reviews.\")\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape all apps\n",
    "all_data = {}\n",
    "\n",
    "for app_name, app_id in APPS.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Scraping: {app_name} ({app_id})\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    app_reviews = scrape_app_reviews(app_name, app_id)\n",
    "    all_data[app_name] = app_reviews\n",
    "    \n",
    "    print(f\"Total reviews collected: {len(app_reviews)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Convert to DataFrames and save\ncombined_dfs = []\n\nfor app_name, app_reviews in all_data.items():\n    df = pd.DataFrame(app_reviews)\n    df[\"app_name\"] = app_name\n    \n    # Select and rename useful columns\n    columns = [\n        \"reviewId\", \"userName\", \"content\", \"score\", \"thumbsUpCount\",\n        \"reviewCreatedVersion\", \"at\", \"replyContent\", \"repliedAt\", \"app_name\"\n    ]\n    df = df[[c for c in columns if c in df.columns]]\n    \n    # Save per-app CSV with date tag\n    filename = f\"{OUTPUT_DIR}/{app_name}_reviews_{RUN_DATE}.csv\"\n    df.to_csv(filename, index=False)\n    print(f\"Saved {len(df)} reviews to {filename}\")\n    \n    combined_dfs.append(df)\n\n# Save combined CSV\ndf_all = pd.concat(combined_dfs, ignore_index=True)\n\n# Remove duplicates by reviewId\nbefore = len(df_all)\ndf_all = df_all.drop_duplicates(subset=\"reviewId\")\nafter = len(df_all)\nif before != after:\n    print(f\"Removed {before - after} duplicate reviews.\")\n\ncombined_file = f\"{OUTPUT_DIR}/all_reviews_{RUN_DATE}.csv\"\ndf_all.to_csv(combined_file, index=False)\nprint(f\"\\nSaved combined {len(df_all)} reviews to {combined_file}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCRAPING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for app_name in APPS:\n",
    "    count = len(df_all[df_all[\"app_name\"] == app_name])\n",
    "    print(f\"{app_name}: {count} reviews\")\n",
    "print(f\"\\nTotal: {len(df_all)} reviews\")\n",
    "print(f\"Date range: {df_all['at'].min()} to {df_all['at'].max()}\")\n",
    "print(f\"Score distribution:\\n{df_all['score'].value_counts().sort_index()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}