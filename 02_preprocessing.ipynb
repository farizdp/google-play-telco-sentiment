{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 02 - Preprocessing Reviews (Optional)\n\n> **Note:** Preprocessing is now integrated into `01_scrape_reviews.ipynb`. The scraper outputs already-cleaned data with `content_clean` and `language` columns, and saves processed files directly to `data/processed/`.\n>\n> This notebook is kept as a **reference/standalone tool** — useful if you need to re-process raw data separately without re-scraping.\n\nClean and prepare scraped reviews:\n- Remove nulls and duplicates\n- Clean text (whitespace, special characters, unicode)\n- Detect language and optionally translate non-English reviews"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport re\nimport unicodedata\nfrom datetime import datetime\nfrom langdetect import detect, LangDetectException\nimport os"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load raw data — update filename to match the scraper output date tag\nINPUT_FILE = \"data/raw/all_reviews.csv\"  # Update with date tag, e.g. all_reviews_20260217.csv\nOUTPUT_DIR = \"data/processed\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Version/date tag for output files\nRUN_DATE = datetime.now().strftime(\"%Y%m%d\")\n\n# Auto-detect latest raw file if default doesn't exist\nif not os.path.exists(INPUT_FILE):\n    import glob\n    raw_files = sorted(glob.glob(\"data/raw/all_reviews_*.csv\"))\n    if raw_files:\n        INPUT_FILE = raw_files[-1]\n        print(f\"Using latest raw file: {INPUT_FILE}\")\n\ndf = pd.read_csv(INPUT_FILE, parse_dates=[\"at\"])\nprint(f\"Loaded {len(df)} reviews from {INPUT_FILE}\")\nprint(f\"Output file tag: {RUN_DATE}\")\nprint(f\"Columns: {list(df.columns)}\")\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data quality before cleaning\n",
    "print(\"=\" * 40)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Null content: {df['content'].isna().sum()}\")\n",
    "print(f\"Empty content: {(df['content'].str.strip() == '').sum() if df['content'].notna().any() else 0}\")\n",
    "print(f\"Duplicate reviewIds: {df['reviewId'].duplicated().sum()}\")\n",
    "print(f\"\\nReviews per app:\")\n",
    "print(df['app_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean review text.\"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Normalize unicode characters\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    \n",
    "    # Replace newlines and tabs with space\n",
    "    text = re.sub(r\"[\\n\\r\\t]+\", \" \", text)\n",
    "    \n",
    "    # Remove emojis and special unicode symbols (keep basic punctuation)\n",
    "    text = re.sub(\n",
    "        r\"[\\U00010000-\\U0010ffff]\",  # Supplementary Unicode planes (emojis etc)\n",
    "        \"\",\n",
    "        text,\n",
    "    )\n",
    "    \n",
    "    # Remove excessive punctuation repetition (e.g., \"!!!!!!\" -> \"!\")\n",
    "    text = re.sub(r\"([!?.])\\1{2,}\", r\"\\1\", text)\n",
    "    \n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove duplicates\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=\"reviewId\")\n",
    "print(f\"Removed {before - len(df)} duplicates. Remaining: {len(df)}\")\n",
    "\n",
    "# Step 2: Remove null/empty content\n",
    "df = df.dropna(subset=[\"content\"])\n",
    "df = df[df[\"content\"].str.strip() != \"\"]\n",
    "print(f\"After removing empty reviews: {len(df)}\")\n",
    "\n",
    "# Step 3: Clean text\n",
    "df[\"content_clean\"] = df[\"content\"].apply(clean_text)\n",
    "\n",
    "# Remove rows where cleaning resulted in empty text\n",
    "df = df[df[\"content_clean\"].str.len() > 0]\n",
    "print(f\"After text cleaning: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Detect language\n",
    "def detect_language(text):\n",
    "    \"\"\"Detect language of text. Returns language code or 'unknown'.\"\"\"\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "print(\"Detecting languages...\")\n",
    "df[\"language\"] = df[\"content_clean\"].apply(detect_language)\n",
    "\n",
    "print(f\"\\nLanguage distribution (top 10):\")\n",
    "print(df[\"language\"].value_counts().head(10))\n",
    "\n",
    "en_count = (df[\"language\"] == \"en\").sum()\n",
    "print(f\"\\nEnglish reviews: {en_count} ({en_count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 5: Save processed data\noutput_file = f\"{OUTPUT_DIR}/reviews_cleaned_{RUN_DATE}.csv\"\ndf.to_csv(output_file, index=False)\nprint(f\"Saved {len(df)} cleaned reviews to {output_file}\")\n\n# Also save English-only subset for sentiment analysis\ndf_en = df[df[\"language\"] == \"en\"]\nen_file = f\"{OUTPUT_DIR}/reviews_english_{RUN_DATE}.csv\"\ndf_en.to_csv(en_file, index=False)\nprint(f\"Saved {len(df_en)} English reviews to {en_file}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total cleaned reviews: {len(df)}\")\n",
    "print(f\"English reviews: {len(df_en)}\")\n",
    "print(f\"\\nPer app:\")\n",
    "for app in df[\"app_name\"].unique():\n",
    "    total = len(df[df[\"app_name\"] == app])\n",
    "    en = len(df_en[df_en[\"app_name\"] == app])\n",
    "    print(f\"  {app}: {total} total, {en} English\")\n",
    "\n",
    "# Show sample cleaned reviews\n",
    "print(f\"\\nSample cleaned reviews:\")\n",
    "df[[\"app_name\", \"content_clean\", \"score\", \"language\"]].sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}